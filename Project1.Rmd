---
title: "SCS project1 draft"
output: html_notebook
---

```{r}
library(caret)

#change this to whatever your own directory is 
source("~/Desktop/SCSProj1/stylometryfunctions.R")

# as above
M <- loadCorpus("~/Desktop/SCSProj1/FunctionWords/", "frequentwords70")

set.seed(12345L)
```

```{r}
# discriminant analysis and K-nearest neighbours

traindata <- M$features
testdata <- NULL
testlabels <- NULL

for( i in 1:length(traindata)){
  
  # keep author in training set if they have only the one book
  if (nrow(M$features[[i]]) <= 1){  
    next
  }
  
  #select a random book by this author by choosing a row (= book)
    testind <- sample(1:nrow(traindata[[i]]), 1)

    #add this book to the test set

    testdata <- rbind(testdata, traindata[[i]][testind,])

    testlabels <- c(testlabels, i)

    #now discard the book from the training set

    traindata[[i]] <- traindata[[i]][-testind,,drop=FALSE]
    
}

# obtaining DA prediction and accuracy (naive)
DApreds <- discriminantCorpus(traindata, testdata)
DAacc <- sum(DApreds == testlabels) / length(testlabels)

# obtaining KNN prediction and accuracy (naive)
KNNpreds <- KNNCorpus(traindata, testdata)
KNNacc <- sum(KNNpreds == testlabels) / length(testlabels)


```
---
```{r}
# LOO-CV, may need to do these in separate chunks for both methods.

predictions <- NULL
KNNpredictions <- NULL
truth <- NULL
features <- M$features

# loop over all of the books, adding all but one of them into the training set
# and keeping one out for the test set (j in each loop)
for (i in 1:length(features)) {
  for (j in 1:nrow(features[[i]])) {
    
    testdata <- matrix(features[[i]][j,],nrow=1)
    traindata <- features
    traindata[[i]] <- traindata[[i]][-j,,drop=FALSE]
    
    # skip over authors who dont have enough books in their corpus. 
    if (nrow(traindata[[i]]) == 0){
      next
    }

    DApred <- discriminantCorpus(traindata, testdata)
    predictions <- c(predictions, DApred)
    
    KNNpred <- KNNCorpus(traindata, testdata)
    KNNpredictions <- c(KNNpredictions, KNNpred)
    truth <- c(truth, i)
  }
}

LOOCV_DAaccuracy <- sum(predictions == truth) / length(truth)
LOOCV_KNNaccuracy <- sum(KNNpredictions == truth) / length(truth)
```

```{r}
library(caret)

DAconfusionmatrix <- confusionMatrix(as.factor(DApreds), 
                                     as.factor(testlabels))


```
```{r}
# getting KNN confusion matrix to work (i think it does...)

# turning labels into character dtype
KNNpreds_char <- as.character(KNNpreds)
testlabels_char <- as.character(testlabels)

# making sure the preds are a subset of testlabels
valid_indices <- KNNpreds_char %in% testlabels_char

# getting the valid preds/labels from the character
KNNpreds_valid <- KNNpreds_char[valid_indices]
testlabels_valid <- testlabels_char[valid_indices]

# turning the valid preds/labels back into factors for the output of confusionmatrix 
KNNconfusionmatrix <- confusionMatrix(as.factor(KNNpreds_valid),
                                      as.factor(testlabels_valid))

print("DA confusion matrix:")     
DAconfusionmatrix

print("KNN confusion matrix")
KNNconfusionmatrix


```

```{r}
# finding out who wrote frankenstein, using everything apart from 
# frankenstein in teh training set and just that novel in the test set.
trainset <- M$features[-9]
testset <- M$features[[9]]


frankenstein_da <- discriminantCorpus(trainset, testset)
frankenstein_knn <- KNNCorpus(trainset, testset)

print("DA prediction of author:")
frankenstein_da
print("KNN prediction of author:")
frankenstein_knn

print("reference:")
print(M$authornames)
```
