---
title: "SCS project1 draft"
output: html_notebook
---

```{r}
library(caret)

#change this to whatever your own directory is 
source("~/Desktop/SCSProj1/stylometryfunctions.R")

# as above
M <- loadCorpus("~/Desktop/SCSProj1/FunctionWords/", "frequentwords70")

set.seed(12345L)
```

### The Dataset

The data provided consisted of 'features' which are the word counts for the 70 function words used by each author. These are vectors of 70 elements for each individual book written by the authors. There is also author names which is used to connect the books with the known author of them. 

Authors included in teh data set include Mary Shelley, Percy Shelley, Sir Walter Scott, William Godwin, Bram Stoker, as well as others. Since Percy Shelley was primarily a poet as opposed to a novelist, a selection of his poetry has been included alongside his prose to give a greater quantity of data to draw upon. We have, however, classified Percy Shelley's works into both a poetry and prose authorship in order to better be able to group categorise his work for the reason that the frequency in which one would use function words in both poetry and prose may be quite different. 

There is also works included that are known to be co-authored by Mary and Percy Shelley. Again, these are categorised as joint-authorship and not included in the corpuses of Mary or Percy exclusively. 

```{r} 
#Visualisaiton of the data with mds

x <- NULL
for (i in 1:length(M$features)){
  x <- rbind(x, apply(M$features[[i]], 2, sum))
}

for (i in 1:nrow(x)){
  x[i,] <- x[i,] / sum(x[i,])
}
for (j in 1:ncol(x)) {
  x[,j] <- (x[,j] - mean(x[,j]))/sd(x[,j])
}

d <- dist(x)
pts <- cmdscale(d)
plot(pts,type='n')
text(pts[,1],pts[,2],label=M$authornames,cex=1.5)


```
```{r}
x <- NULL           
doc_authors <- c() 

# Loop over each author
for (i in 1:length(M$features)) {
  current_data <- M$features[[i]]  
  
  # N docs for current author i 
  num_docs <- nrow(current_data)
  
  # add document data to x
  x <- rbind(x, current_data)
  
  # document authors
  doc_authors <- c(doc_authors, rep(M$authornames[i], num_docs))
}

# normalise/standardise data in books
for (i in 1:nrow(x)) {
  x[i, ] <- x[i, ] / sum(x[i, ])
}

for (j in 1:ncol(x)) {
  x[, j] <- (x[, j] - mean(x[, j])) / sd(x[, j])
}

# MDS co-ords
dist_matrix <- dist(x)
pts <- cmdscale(dist_matrix)

# indicator for unknown author
IsAuthor9 <- doc_authors == M$authornames[9]  

## ggplot dataframe
plot_data <- data.frame(
  Dim1 = pts[, 1],
  Dim2 = pts[, 2],
  Author = doc_authors,
  IsAuthor9 = IsAuthor9
)

ggplot(plot_data, aes(x = Dim1, y = Dim2)) +
  geom_point(aes(color = Author, shape = IsAuthor9), size = 4) +
  scale_shape_manual(
    values = c('FALSE' = 16, 'TRUE' = 4),  # 16: circle, 4: 'x'
    labels = c('FALSE' = 'Known Author', 'TRUE' = 'Unknown')
  ) +
  theme_classic() +
  theme(legend.position = "right") +
  guides(
    shape = guide_legend(title = "Document Type"),
    color = guide_legend(override.aes = list(size = 4))
  ) +
  labs(
    title = "MDS Plot of Books",
    x = "Dimension 1",
    y = "Dimension 2"
  )



```
```{r}
# Visualization of the data with MDS

x <- NULL           
doc_authors <- c() 

# Loop over each author
for (i in 1:length(M$features)) {
  current_data <- M$features[[i]]  
  
  # N docs for current author i 
  num_docs <- nrow(current_data)
  
  # add document data to x
  x <- rbind(x, current_data)
  
  # document authors
  doc_authors <- c(doc_authors, rep(M$authornames[i], num_docs))
}

# normalise/standardise data in books
for (i in 1:nrow(x)) {
  x[i, ] <- x[i, ] / sum(x[i, ])
}

for (j in 1:ncol(x)) {
  x[, j] <- (x[, j] - mean(x[, j])) / sd(x[, j])
}

# MDS co-ords
dist_matrix <- dist(x)
pts <- cmdscale(dist_matrix)

# indicator for unknown author
IsAuthor9 <- doc_authors == M$authornames[9]  

## ggplot dataframe
plot_data <- data.frame(
  Dim1 = pts[, 1],
  Dim2 = pts[, 2],
  Author = doc_authors,
  IsAuthor9 = IsAuthor9
)

ggplot(plot_data, aes(x = Dim2, y = Dim1)) +
  geom_point(aes(color = Author, shape = IsAuthor9), size = 4) +
  scale_shape_manual(
    values = c('FALSE' = 16, 'TRUE' = 4),  # 16: circle, 4: 'x'
    labels = c('FALSE' = 'Known Author', 'TRUE' = 'Unknown')
  ) +
  theme_classic() +
  theme(legend.position = "right") +
  guides(
    shape = guide_legend(title = "Document Type"),
    color = guide_legend(override.aes = list(size = 4))
  ) +
  labs(
    title = "MDS Plot of Books",
    x = "Dimension 2",
    y = "Dimension 1"
  )


```
## rough comments about the visualisation

The visualisation indicates that there is significant overlap between many of the authors, particularly Mary Shelley. Notable outliers to this trend include Bram Stoker, an irish novelist who was active much later than the others, Percy Shelley's poetry works which may be due to the relationship previously discussed between word usage differences between prose and poetry, and Charles Brockden Brown who was an american novelist. A difference in nationality and 'accent' might be the root cause of this. The other authors were all active during a similar time period and from the same country. This overlap may cause issues with our classification models, particularly DA as this relies on estimating word frequencies used by authors, and as we can see there appears to be a great deal of variability in this given the apparent lack of distinction between many of the authors. 

Nevertheless, there is enough differentiation between them to be able to be reasonably confident in the methods we implement, although Mary Shelley may cause issues due to her being fairly 'middle of the pack'- her works look to be the most varied stylistically as well as appearing in and around many other authors. 


```{r}
# discriminant analysis and K-nearest neighbours

traindata <- M$features
testdata <- NULL
testlabels <- NULL

for( i in 1:length(traindata)){
  
  # keep author in training set if they have only the one book
  if (nrow(M$features[[i]]) <= 1){  
    next
  }
  
  #select a random book by this author by choosing a row (= book)
    testind <- sample(1:nrow(traindata[[i]]), 1)

    #add this book to the test set

    testdata <- rbind(testdata, traindata[[i]][testind,])

    testlabels <- c(testlabels, i)

    #now discard the book from the training set

    traindata[[i]] <- traindata[[i]][-testind,,drop=FALSE]
    
}

# obtaining DA prediction and accuracy (naive)
DApreds <- discriminantCorpus(traindata, testdata)
DAacc <- sum(DApreds == testlabels) / length(testlabels)

# obtaining KNN prediction and accuracy (naive)
KNNpreds <- KNNCorpus(traindata, testdata)
KNNacc <- sum(KNNpreds == testlabels) / length(testlabels)

RFpreds <- randomForestCorpus(traindata, testdata)
RFacc <- sum(RFpreds == testlabels) / length(testlabels)

```
---
---
```{r}
library(randomForest)

DApredictions <- NULL
KNNpredictions <- NULL
RFpredictions <- NULL
truth <- NULL
features <- M$features

# Filter out authors with only one document
authors_to_keep <- sapply(features, function(x) nrow(x) > 1)
features_filtered <- features[authors_to_keep]

for (i in 1:length(features_filtered)) {
  for (j in 1:nrow(features_filtered[[i]])) {
    testdata <- matrix(features_filtered[[i]][j, ], nrow = 1)
    traindata <- features_filtered
    traindata[[i]] <- traindata[[i]][-j, , drop = FALSE]
    
    pred <- discriminantCorpus(traindata, testdata)
    DApredictions <- c(DApredictions, pred)
    pred <- KNNCorpus(traindata, testdata)
    KNNpredictions <- c(KNNpredictions, pred)
    truth <- c(truth, i)
    
  }
}

LOOCVDAacc<- sum(DApredictions == truth) / length(truth)
LOOCVKNNacc <- sum(KNNpredictions == truth) / length(truth)

print("LOOCV accuracy for DA:")
LOOCVDAacc
print("LOOCV accuracy for KNN:")
LOOCVKNNacc



```
Our LOOCV tests indicate that whilst both do have an acceptable level of accuracy, we should trust 


```{r}
library(caret)

DAconfusionmatrix <- confusionMatrix(as.factor(DApredictions), 
                                     as.factor(truth))

KNNconfusionmatrix <- confusionMatrix(as.factor(KNNpredictions),
                                      as.factor(truth))
print("DA cm:")
DAconfusionmatrix
print("---------------------------------------------")
print("KNN confusion matrix")
KNNconfusionmatrix
```
As we can see, the confusion matrix for discriminant analysis is demonstrating the concern regarding Mary Shelley's writings being in between a lot of other authors, perhaps indicating an explanation as to why there were so many misclassifications (she is class '3' in this because we removed the 1-book authors from the LOOCV to make it work). We can also see that K-NN performs much better in this regard, there are much fewer errors using this method in the cross-validation, as well as the mistake being made is fairly immaterial in regards to the research question. 

## Analysis of Frankenstein

We shall now apply our methods of Stylometry in an attempt to identify the author of Frankenstein. We shall use the entire corpus obtained as the training set, and test the model in both a KNN and DA setting on the Frankenstein novel. Each model choice will make a prediction as to whom the author is. 

```{r}
# finding out who wrote frankenstein, using everything apart from 
# frankenstein in the training set and just that novel in the test set.

trainset <- M$features[-9]
testset <- M$features[[9]]

new_authors <- M$authornames[-9]

frankenstein_da <- discriminantCorpus(trainset, testset)
frankenstein_knn <- KNNCorpus(trainset, testset)

print("DA prediction of author:")
new_authors[frankenstein_da]
print("KNN prediction of author:")
new_authors[frankenstein_knn]
```
Here we observe that there is disagreement between the models, with discriminant analysis predicting that William Godwin was the true author of Frankenstein, whilst the K-nearest-neighbours methodology predicts that Mary Shelley is the author of the novel. However from our cross-validation we have observed that KNN is far superior for identifying authorship on this dataset than discriminant analysis is. For example, viewing the confusion matrix above indicated that many books using discriminant analysis were misidentified as being the work of Mary Shelley, including one of Godwin's own books. K-nearest neighbours does not, however, have the same issues, demonstrating a high degree of accuracy when tested using cross-validation methods.

There may also be a degree of uncertainty regarding the DA classification of the author of Frankenstein. This may be for reasons such as Frankenstein being 

Therefore, this leads up to trust the classification given by KNN more so than that given by Discriminant Analysis. Hence, we are more confident in the assertion that Mary Shelley wrote Frankenstein than any other author given as a result of our Stylometric analysis and validation of the methodology used to arrive at this conclusion.  
























```{r}
# thiis is just for working out the theta values given to see how they compare with one another for 1)William Godwin 2)Frankenstein 3)Mary SHelley. 
wp_thetas <- NULL
wp_books <- M$features[11]
wp_words <- apply(M$features[[11]], 2, sum)
inds <- which(wp_words==0) 
if (length(inds) > 0) {wp_words[inds] <- 1}
wp_thetas <- rbind(wp_thetas, wp_words/sum(wp_words))

wp_thetas

fr_thetas <- NULL
fr_book <- M$features[9]
fr_words <- apply(M$features[[9]], 2, sum)
Inds <- which(fr_words==0)
if (length(Inds)>0) {fr_words[Inds] <- 1}
fr_thetas <- rbind(fr_thetas, fr_words / sum(fr_words))

fr_thetas

ms_thetas <- NULL
ms_books <- M$features[4]
ms_words <- apply(M$features[[4]], 2, sum)
iinds <- which(ms_words == 0)
if (length(iinds)>0) {ms_words[iinds] <-1}
ms_thetas <- rbind(ms_thetas, ms_words / sum(ms_words))

rbind(fr_thetas, wp_thetas, ms_thetas)
dmultinom(x = fr_book[[1]], prob = wp_thetas, log=F)
```
 













```{r}
# This is just for testing some things, NOT IMPORTANT #

discriminantCorpus1 <- function(traindata, testdata) {
  thetas <- NULL
  
  # First, learn the model for each author
  for (i in 1:length(traindata)) {
    words <- apply(traindata[[i]], 2, sum)
    
    # Ensure no word has a zero count
    words[words == 0] <- 1
    thetas <- rbind(thetas, words / sum(words))
  }
  
  # Now classify
  preds <- matrix(0, nrow = nrow(testdata), ncol = nrow(thetas))
  for (i in 1:nrow(testdata)) {
    for (j in 1:nrow(thetas)) {
      preds[i, j] <- dmultinom(testdata[i, ], prob = thetas[j, ], log = TRUE)
    }
  }
  return(preds)
}

preds <- discriminantCorpus1(trainset, testset)
preds
# Compute probabilities
probs <- t(apply(preds, 1, function(log_likelihoods) {
  # Adjust log-likelihoods to prevent numerical underflow
  max_ll <- max(log_likelihoods)
  adjusted_lls <- log_likelihoods - max_ll
  likelihoods <- exp(adjusted_lls)
  # Normalize to get probabilities
  probabilities <- likelihoods / sum(likelihoods)
  return(probabilities)
}))
randomForestCorpus(trainset, testset)
probs #the other method in the package got it right tho???
```


